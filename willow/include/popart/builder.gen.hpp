// Copyright (c) 2018 Graphcore Ltd. All rights reserved.
/*
 * THIS IS AN AUTOGENERATED FILE, DO NOT EDIT DIRECTLY
 *
 * To regenerate this file run the gen_operators.py script
 */
#ifndef GUARD_NEURALNET_BUILDER_GEN_HPP_
#define GUARD_NEURALNET_BUILDER_GEN_HPP_

#include <cstdint>
#include <memory>
#include <string>
#include <vector>

#include "popart/debugcontext.hpp"
#include "popart/domainopset.hpp"
#include "popart/names.hpp"
#include "popart/vendored/optional.hpp"

namespace popart {
class Builder;
class BuilderImpl;
class ConstVoidData;

class AiOnnxOpset6 : private DomainOpSet {

protected:
  using DomainOpSet::impl;

public:
  AiOnnxOpset6(std::unique_ptr<BuilderImpl> &impl_) : DomainOpSet(impl_) {}

  // return the opset version
  int getOpsetVersion() const override { return 6; }

  /**
   * Add the 'Abs' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Abs
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId abs(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Add' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Add-6
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param broadcast The 'broadcast' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId add(const std::vector<TensorId> &args,
               nonstd::optional<int64_t> axis = nonstd::optional<int64_t>(),
               int64_t broadcast              = 0,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'And' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#And-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param broadcast The 'broadcast' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  logical_and(const std::vector<TensorId> &args,
              nonstd::optional<int64_t> axis = nonstd::optional<int64_t>(),
              int64_t broadcast              = 0,
              const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ArgMax' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#ArgMax-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId argmax(const std::vector<TensorId> &args,
                  int64_t axis                             = 0,
                  int64_t keepdims                         = 1,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ArgMin' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#ArgMin-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId argmin(const std::vector<TensorId> &args,
                  int64_t axis                             = 0,
                  int64_t keepdims                         = 1,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'AveragePool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#AveragePool-1
   *
   * \param args List of input tensor ids
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  averagepool(const std::vector<TensorId> &args,
              const std::vector<int64_t> &kernel_shape,
              const std::vector<int64_t> &pads         = std::vector<int64_t>(),
              const std::vector<int64_t> &strides      = std::vector<int64_t>(),
              const popart::DebugContext &debugContext = {});

  /**
   * Add the 'BatchNormalization' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#BatchNormalization-6
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param epsilon The 'epsilon' attribute
   * \param is_test The 'is_test' attribute
   * \param momentum The 'momentum' attribute
   * \param spatial The 'spatial' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  batchnormalization(const std::vector<TensorId> &args,
                     unsigned num_outputs,
                     float epsilon                            = 1e-05f,
                     int64_t is_test                          = 0,
                     float momentum                           = 0.9f,
                     int64_t spatial                          = 1,
                     const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Cast' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Cast-6
   *
   * \param args List of input tensor ids
   * \param to The 'to' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId cast(const std::vector<TensorId> &args,
                const std::string &to,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Ceil' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Ceil
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId ceil(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Clip' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Clip-6
   *
   * \param args List of input tensor ids
   * \param max The 'max' attribute
   * \param min The 'min' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId clip(const std::vector<TensorId> &args,
                float max = 3.4028234663852886e+38f,
                float min = -3.4028234663852886e+38f,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Concat' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Concat-4
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId concat(const std::vector<TensorId> &args,
                  int64_t axis,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Constant' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Constant-1
   *
   * \param value The 'value' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId constant(const ConstVoidData &value,
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Conv' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Conv-1
   *
   * \param args List of input tensor ids
   * \param dilations The 'dilations' attribute
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param group The 'group' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  conv(const std::vector<TensorId> &args,
       const std::vector<int64_t> &dilations    = std::vector<int64_t>(),
       int64_t group                            = 1,
       const std::vector<int64_t> &kernel_shape = std::vector<int64_t>(),
       const std::vector<int64_t> &pads         = std::vector<int64_t>(),
       const std::vector<int64_t> &strides      = std::vector<int64_t>(),
       const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ConvTranspose' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#ConvTranspose-1
   *
   * \param args List of input tensor ids
   * \param dilations The 'dilations' attribute
   * \param kernel_shape The 'kernel_shape' attribute
   * \param output_padding The 'output_padding' attribute
   * \param output_shape The 'output_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param group The 'group' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId convtranspose(
      const std::vector<TensorId> &args,
      const std::vector<int64_t> &dilations      = std::vector<int64_t>(),
      int64_t group                              = 1,
      const std::vector<int64_t> &kernel_shape   = std::vector<int64_t>(),
      const std::vector<int64_t> &output_padding = std::vector<int64_t>(),
      const std::vector<int64_t> &output_shape   = std::vector<int64_t>(),
      const std::vector<int64_t> &pads           = std::vector<int64_t>(),
      const std::vector<int64_t> &strides        = std::vector<int64_t>(),
      const popart::DebugContext &debugContext   = {});

  /**
   * Add the 'DepthToSpace' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#DepthToSpace-1
   *
   * \param args List of input tensor ids
   * \param blocksize The 'blocksize' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId depthtospace(const std::vector<TensorId> &args,
                        int64_t blocksize,
                        const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Div' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Div-6
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param broadcast The 'broadcast' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId div(const std::vector<TensorId> &args,
               nonstd::optional<int64_t> axis = nonstd::optional<int64_t>(),
               int64_t broadcast              = 0,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Dropout' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Dropout-6
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param is_test The 'is_test' attribute
   * \param ratio The 'ratio' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId> dropout(const std::vector<TensorId> &args,
                                unsigned num_outputs,
                                int64_t is_test                          = 0,
                                float ratio                              = 0.5f,
                                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Elu' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Elu
   *
   * \param args List of input tensor ids
   * \param alpha The 'alpha' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId elu(const std::vector<TensorId> &args,
               float alpha                              = 1.0f,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Equal' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Equal-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param broadcast The 'broadcast' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId equal(const std::vector<TensorId> &args,
                 nonstd::optional<int64_t> axis = nonstd::optional<int64_t>(),
                 int64_t broadcast              = 0,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Exp' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Exp
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId exp(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Flatten' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Flatten-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId flatten(const std::vector<TensorId> &args,
                   int64_t axis                             = 1,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Floor' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Floor
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId floor(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'GRU' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#GRU-3
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param activation_alpha The 'activation_alpha' attribute
   * \param activation_beta The 'activation_beta' attribute
   * \param activations The 'activations' attribute
   * \param clip The 'clip' attribute
   * \param hidden_size The 'hidden_size' attribute
   * \param direction The 'direction' attribute
   * \param linear_before_reset The 'linear_before_reset' attribute
   * \param output_sequence The 'output_sequence' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  gru(const std::vector<TensorId> &args,
      unsigned num_outputs,
      const std::vector<float> &activation_alpha  = std::vector<float>(),
      const std::vector<float> &activation_beta   = std::vector<float>(),
      const std::vector<std::string> &activations = std::vector<std::string>(),
      nonstd::optional<float> clip                = nonstd::optional<float>(),
      const std::string &direction                = "forward",
      nonstd::optional<int64_t> hidden_size       = nonstd::optional<int64_t>(),
      int64_t linear_before_reset                 = 0,
      int64_t output_sequence                     = 0,
      const popart::DebugContext &debugContext    = {});

  /**
   * Add the 'Gather' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Gather-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId gather(const std::vector<TensorId> &args,
                  int64_t axis                             = 0,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Gemm' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Gemm-6
   *
   * \param args List of input tensor ids
   * \param alpha The 'alpha' attribute
   * \param beta The 'beta' attribute
   * \param broadcast The 'broadcast' attribute
   * \param transA The 'transA' attribute
   * \param transB The 'transB' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId gemm(const std::vector<TensorId> &args,
                float alpha                              = 1.0f,
                float beta                               = 1.0f,
                int64_t broadcast                        = 0,
                int64_t transA                           = 0,
                int64_t transB                           = 0,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'GlobalAveragePool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#GlobalAveragePool
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId globalaveragepool(const std::vector<TensorId> &args,
                             const popart::DebugContext &debugContext = {});

  /**
   * Add the 'GlobalLpPool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#GlobalLpPool
   *
   * \param args List of input tensor ids
   * \param p The 'p' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId globallppool(const std::vector<TensorId> &args,
                        int64_t p                                = 2,
                        const popart::DebugContext &debugContext = {});

  /**
   * Add the 'GlobalMaxPool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#GlobalMaxPool
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId globalmaxpool(const std::vector<TensorId> &args,
                         const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Greater' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Greater-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param broadcast The 'broadcast' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId greater(const std::vector<TensorId> &args,
                   nonstd::optional<int64_t> axis = nonstd::optional<int64_t>(),
                   int64_t broadcast              = 0,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'HardSigmoid' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#HardSigmoid
   *
   * \param args List of input tensor ids
   * \param alpha The 'alpha' attribute
   * \param beta The 'beta' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId hardsigmoid(const std::vector<TensorId> &args,
                       float alpha                              = 0.2f,
                       float beta                               = 0.5f,
                       const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Hardmax' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Hardmax-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId hardmax(const std::vector<TensorId> &args,
                   int64_t axis                             = 1,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Identity' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Identity
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId identity(const std::vector<TensorId> &args,
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'If' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#If-1
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param else_branch The 'else_branch' attribute
   * \param then_branch The 'then_branch' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  std::vector<TensorId>
  logical_if(const std::vector<TensorId> &args,
             unsigned num_outputs,
             const Builder &else_branch,
             const Builder &then_branch,
             const popart::DebugContext &debugContext = {});

  /**
   * Add the 'InstanceNormalization' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#InstanceNormalization
   *
   * \param args List of input tensor ids
   * \param epsilon The 'epsilon' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId instancenormalization(const std::vector<TensorId> &args,
                                 float epsilon = 1e-05f,
                                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'LRN' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#LRN
   *
   * \param args List of input tensor ids
   * \param size The 'size' attribute
   * \param alpha The 'alpha' attribute
   * \param beta The 'beta' attribute
   * \param bias The 'bias' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId lrn(const std::vector<TensorId> &args,
               int64_t size,
               float alpha                              = 0.0001f,
               float beta                               = 0.75f,
               float bias                               = 1.0f,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'LSTM' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#LSTM-1
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param activation_alpha The 'activation_alpha' attribute
   * \param activation_beta The 'activation_beta' attribute
   * \param activations The 'activations' attribute
   * \param clip The 'clip' attribute
   * \param hidden_size The 'hidden_size' attribute
   * \param direction The 'direction' attribute
   * \param input_forget The 'input_forget' attribute
   * \param output_sequence The 'output_sequence' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  lstm(const std::vector<TensorId> &args,
       unsigned num_outputs,
       const std::vector<float> &activation_alpha  = std::vector<float>(),
       const std::vector<float> &activation_beta   = std::vector<float>(),
       const std::vector<std::string> &activations = std::vector<std::string>(),
       nonstd::optional<float> clip                = nonstd::optional<float>(),
       const std::string &direction                = "forward",
       nonstd::optional<int64_t> hidden_size    = nonstd::optional<int64_t>(),
       int64_t input_forget                     = 0,
       int64_t output_sequence                  = 0,
       const popart::DebugContext &debugContext = {});

  /**
   * Add the 'LeakyRelu' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#LeakyRelu
   *
   * \param args List of input tensor ids
   * \param alpha The 'alpha' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId leakyrelu(const std::vector<TensorId> &args,
                     float alpha                              = 0.01f,
                     const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Less' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Less-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param broadcast The 'broadcast' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId less(const std::vector<TensorId> &args,
                nonstd::optional<int64_t> axis = nonstd::optional<int64_t>(),
                int64_t broadcast              = 0,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Log' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Log
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId log(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'LogSoftmax' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#LogSoftmax-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId logsoftmax(const std::vector<TensorId> &args,
                      int64_t axis                             = 1,
                      const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Loop' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Loop-1
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param body The 'body' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  std::vector<TensorId> loop(const std::vector<TensorId> &args,
                             unsigned num_outputs,
                             const Builder &body,
                             const popart::DebugContext &debugContext = {});

  /**
   * Add the 'LpNormalization' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#LpNormalization
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param p The 'p' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId lpnormalization(const std::vector<TensorId> &args,
                           int64_t axis                             = -1,
                           int64_t p                                = 2,
                           const popart::DebugContext &debugContext = {});

  /**
   * Add the 'LpPool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#LpPool-2
   *
   * \param args List of input tensor ids
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param p The 'p' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId lppool(const std::vector<TensorId> &args,
                  const std::vector<int64_t> &kernel_shape,
                  int64_t p                           = 2,
                  const std::vector<int64_t> &pads    = std::vector<int64_t>(),
                  const std::vector<int64_t> &strides = std::vector<int64_t>(),
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'MatMul' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#MatMul-1
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId matmul(const std::vector<TensorId> &args,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Max' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Max-6
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId max(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'MaxPool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#MaxPool-1
   *
   * \param args List of input tensor ids
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId maxpool(const std::vector<TensorId> &args,
                   const std::vector<int64_t> &kernel_shape,
                   const std::vector<int64_t> &pads    = std::vector<int64_t>(),
                   const std::vector<int64_t> &strides = std::vector<int64_t>(),
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'MaxRoiPool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#MaxRoiPool
   *
   * \param args List of input tensor ids
   * \param pooled_shape The 'pooled_shape' attribute
   * \param spatial_scale The 'spatial_scale' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId maxroipool(const std::vector<TensorId> &args,
                      const std::vector<int64_t> &pooled_shape,
                      float spatial_scale                      = 1.0f,
                      const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Mean' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Mean-6
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId mean(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Min' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Min-6
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId min(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Mul' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Mul-6
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param broadcast The 'broadcast' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId mul(const std::vector<TensorId> &args,
               nonstd::optional<int64_t> axis = nonstd::optional<int64_t>(),
               int64_t broadcast              = 0,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Neg' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Neg
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId neg(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Not' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Not
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId logical_not(const std::vector<TensorId> &args,
                       const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Or' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Or-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param broadcast The 'broadcast' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  logical_or(const std::vector<TensorId> &args,
             nonstd::optional<int64_t> axis = nonstd::optional<int64_t>(),
             int64_t broadcast              = 0,
             const popart::DebugContext &debugContext = {});

  /**
   * Add the 'PRelu' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#PRelu-6
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId prelu(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Pad' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Pad-2
   *
   * \param args List of input tensor ids
   * \param pads The 'pads' attribute
   * \param mode The 'mode' attribute
   * \param value The 'value' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId pad(const std::vector<TensorId> &args,
               const std::vector<int64_t> &pads,
               const std::string &mode                  = "constant",
               float value                              = 0.0f,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Pow' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Pow-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param broadcast The 'broadcast' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId pow(const std::vector<TensorId> &args,
               nonstd::optional<int64_t> axis = nonstd::optional<int64_t>(),
               int64_t broadcast              = 0,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'RNN' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#RNN-1
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param activation_alpha The 'activation_alpha' attribute
   * \param activation_beta The 'activation_beta' attribute
   * \param clip The 'clip' attribute
   * \param hidden_size The 'hidden_size' attribute
   * \param activations The 'activations' attribute
   * \param direction The 'direction' attribute
   * \param output_sequence The 'output_sequence' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  rnn(const std::vector<TensorId> &args,
      unsigned num_outputs,
      const std::vector<float> &activation_alpha  = std::vector<float>(),
      const std::vector<float> &activation_beta   = std::vector<float>(),
      const std::vector<std::string> &activations = std::vector<std::string>(),
      nonstd::optional<float> clip                = nonstd::optional<float>(),
      const std::string &direction                = "forward",
      nonstd::optional<int64_t> hidden_size       = nonstd::optional<int64_t>(),
      int64_t output_sequence                     = 0,
      const popart::DebugContext &debugContext    = {});

  /**
   * Add the 'RandomNormal' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomNormal
   *
   * \param seed The 'seed' attribute
   * \param shape The 'shape' attribute
   * \param dtype The 'dtype' attribute
   * \param mean The 'mean' attribute
   * \param scale The 'scale' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  randomnormal(const std::vector<int64_t> &shape,
               int64_t dtype                = 1,
               float mean                   = 0.0f,
               float scale                  = 1.0f,
               nonstd::optional<float> seed = nonstd::optional<float>(),
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'RandomNormalLike' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomNormalLike
   *
   * \param args List of input tensor ids
   * \param dtype The 'dtype' attribute
   * \param seed The 'seed' attribute
   * \param mean The 'mean' attribute
   * \param scale The 'scale' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId randomnormallike(
      const std::vector<TensorId> &args,
      nonstd::optional<int64_t> dtype          = nonstd::optional<int64_t>(),
      float mean                               = 0.0f,
      float scale                              = 1.0f,
      nonstd::optional<float> seed             = nonstd::optional<float>(),
      const popart::DebugContext &debugContext = {});

  /**
   * Add the 'RandomUniform' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomUniform
   *
   * \param seed The 'seed' attribute
   * \param shape The 'shape' attribute
   * \param dtype The 'dtype' attribute
   * \param high The 'high' attribute
   * \param low The 'low' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  randomuniform(const std::vector<int64_t> &shape,
                int64_t dtype                = 1,
                float high                   = 1.0f,
                float low                    = 0.0f,
                nonstd::optional<float> seed = nonstd::optional<float>(),
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'RandomUniformLike' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomUniformLike
   *
   * \param args List of input tensor ids
   * \param dtype The 'dtype' attribute
   * \param seed The 'seed' attribute
   * \param high The 'high' attribute
   * \param low The 'low' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId randomuniformlike(
      const std::vector<TensorId> &args,
      nonstd::optional<int64_t> dtype          = nonstd::optional<int64_t>(),
      float high                               = 1.0f,
      float low                                = 0.0f,
      nonstd::optional<float> seed             = nonstd::optional<float>(),
      const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Reciprocal' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Reciprocal
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reciprocal(const std::vector<TensorId> &args,
                      const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceL1' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#ReduceL1-1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducel1(const std::vector<TensorId> &args,
                    nonstd::optional<std::vector<int64_t>> axes =
                        nonstd::optional<std::vector<int64_t>>(),
                    int64_t keepdims                         = 1,
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceL2' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#ReduceL2-1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducel2(const std::vector<TensorId> &args,
                    nonstd::optional<std::vector<int64_t>> axes =
                        nonstd::optional<std::vector<int64_t>>(),
                    int64_t keepdims                         = 1,
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceLogSum' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#ReduceLogSum-1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducelogsum(const std::vector<TensorId> &args,
                        nonstd::optional<std::vector<int64_t>> axes =
                            nonstd::optional<std::vector<int64_t>>(),
                        int64_t keepdims                         = 1,
                        const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceLogSumExp' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#ReduceLogSumExp-1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducelogsumexp(const std::vector<TensorId> &args,
                           nonstd::optional<std::vector<int64_t>> axes =
                               nonstd::optional<std::vector<int64_t>>(),
                           int64_t keepdims                         = 1,
                           const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceMax' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#ReduceMax-1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducemax(const std::vector<TensorId> &args,
                     nonstd::optional<std::vector<int64_t>> axes =
                         nonstd::optional<std::vector<int64_t>>(),
                     int64_t keepdims                         = 1,
                     const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceMean' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#ReduceMean-1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducemean(const std::vector<TensorId> &args,
                      nonstd::optional<std::vector<int64_t>> axes =
                          nonstd::optional<std::vector<int64_t>>(),
                      int64_t keepdims                         = 1,
                      const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceMin' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#ReduceMin-1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducemin(const std::vector<TensorId> &args,
                     nonstd::optional<std::vector<int64_t>> axes =
                         nonstd::optional<std::vector<int64_t>>(),
                     int64_t keepdims                         = 1,
                     const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceProd' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#ReduceProd-1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reduceprod(const std::vector<TensorId> &args,
                      nonstd::optional<std::vector<int64_t>> axes =
                          nonstd::optional<std::vector<int64_t>>(),
                      int64_t keepdims                         = 1,
                      const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceSum' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#ReduceSum-1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducesum(const std::vector<TensorId> &args,
                     nonstd::optional<std::vector<int64_t>> axes =
                         nonstd::optional<std::vector<int64_t>>(),
                     int64_t keepdims                         = 1,
                     const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceSumSquare' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#ReduceSumSquare-1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducesumsquare(const std::vector<TensorId> &args,
                           nonstd::optional<std::vector<int64_t>> axes =
                               nonstd::optional<std::vector<int64_t>>(),
                           int64_t keepdims                         = 1,
                           const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Relu' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Relu
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId relu(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Reshape' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Reshape
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reshape(const std::vector<TensorId> &args,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Selu' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Selu
   *
   * \param args List of input tensor ids
   * \param alpha The 'alpha' attribute
   * \param gamma The 'gamma' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId selu(const std::vector<TensorId> &args,
                float alpha                              = 1.67326f,
                float gamma                              = 1.0507f,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Shape' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Shape
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId shape(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Sigmoid' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sigmoid
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sigmoid(const std::vector<TensorId> &args,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Size' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Size
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId size(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Slice' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Slice-1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param ends The 'ends' attribute
   * \param starts The 'starts' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId slice(const std::vector<TensorId> &args,
                 const std::vector<int64_t> &ends,
                 const std::vector<int64_t> &starts,
                 const std::vector<int64_t> &axes = std::vector<int64_t>(),
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Softmax' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Softmax-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId softmax(const std::vector<TensorId> &args,
                   int64_t axis                             = 1,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Softplus' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Softplus
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId softplus(const std::vector<TensorId> &args,
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Softsign' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Softsign
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId softsign(const std::vector<TensorId> &args,
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'SpaceToDepth' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#SpaceToDepth
   *
   * \param args List of input tensor ids
   * \param blocksize The 'blocksize' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId spacetodepth(const std::vector<TensorId> &args,
                        int64_t blocksize,
                        const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Split' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Split-2
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param split The 'split' attribute
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  std::vector<TensorId>
  split(const std::vector<TensorId> &args,
        unsigned num_outputs,
        int64_t axis                             = 0,
        const std::vector<int64_t> &split        = std::vector<int64_t>(),
        const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Sqrt' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sqrt
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sqrt(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Squeeze' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Squeeze-1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId squeeze(const std::vector<TensorId> &args,
                   const std::vector<int64_t> &axes = std::vector<int64_t>(),
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Sub' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Sub-6
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param broadcast The 'broadcast' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sub(const std::vector<TensorId> &args,
               nonstd::optional<int64_t> axis = nonstd::optional<int64_t>(),
               int64_t broadcast              = 0,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Sum' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Sum-6
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sum(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Tanh' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Tanh
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId tanh(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Tile' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Tile
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId tile(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'TopK' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#TopK-1
   *
   * \param args List of input tensor ids
   * \param k The 'k' attribute
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId> topk(const std::vector<TensorId> &args,
                             int64_t k,
                             int64_t axis                             = -1,
                             const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Transpose' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Transpose
   *
   * \param args List of input tensor ids
   * \param perm The 'perm' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId transpose(const std::vector<TensorId> &args,
                     const std::vector<int64_t> &perm = std::vector<int64_t>(),
                     const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Unsqueeze' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Unsqueeze-1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId unsqueeze(const std::vector<TensorId> &args,
                     const std::vector<int64_t> &axes,
                     const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Upsample' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Upsample-1
   *
   * \param args List of input tensor ids
   * \param height_scale The 'height_scale' attribute
   * \param width_scale The 'width_scale' attribute
   * \param mode The 'mode' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId upsample(const std::vector<TensorId> &args,
                    float height_scale,
                    float width_scale,
                    const std::string &mode                  = "nearest",
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Xor' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Xor-1
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param broadcast The 'broadcast' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  logical_xor(const std::vector<TensorId> &args,
              nonstd::optional<int64_t> axis = nonstd::optional<int64_t>(),
              int64_t broadcast              = 0,
              const popart::DebugContext &debugContext = {});
};

class AiOnnxOpset7 : private AiOnnxOpset6 {

protected:
  using AiOnnxOpset6::impl;

public:
  AiOnnxOpset7(std::unique_ptr<BuilderImpl> &impl_) : AiOnnxOpset6(impl_) {}

  // return the opset version
  int getOpsetVersion() const override { return 7; }

  using AiOnnxOpset6::abs;
  using AiOnnxOpset6::argmax;
  using AiOnnxOpset6::argmin;
  using AiOnnxOpset6::cast;
  using AiOnnxOpset6::ceil;
  using AiOnnxOpset6::clip;
  using AiOnnxOpset6::concat;
  using AiOnnxOpset6::constant;
  using AiOnnxOpset6::conv;
  using AiOnnxOpset6::convtranspose;
  using AiOnnxOpset6::depthtospace;
  using AiOnnxOpset6::elu;
  using AiOnnxOpset6::exp;
  using AiOnnxOpset6::flatten;
  using AiOnnxOpset6::floor;
  using AiOnnxOpset6::gather;
  using AiOnnxOpset6::globalaveragepool;
  using AiOnnxOpset6::globallppool;
  using AiOnnxOpset6::globalmaxpool;
  using AiOnnxOpset6::hardmax;
  using AiOnnxOpset6::hardsigmoid;
  using AiOnnxOpset6::identity;
  using AiOnnxOpset6::instancenormalization;
  using AiOnnxOpset6::leakyrelu;
  using AiOnnxOpset6::log;
  using AiOnnxOpset6::logical_if;
  using AiOnnxOpset6::logical_not;
  using AiOnnxOpset6::logsoftmax;
  using AiOnnxOpset6::loop;
  using AiOnnxOpset6::lpnormalization;
  using AiOnnxOpset6::lppool;
  using AiOnnxOpset6::lrn;
  using AiOnnxOpset6::matmul;
  using AiOnnxOpset6::max;
  using AiOnnxOpset6::maxpool;
  using AiOnnxOpset6::maxroipool;
  using AiOnnxOpset6::mean;
  using AiOnnxOpset6::min;
  using AiOnnxOpset6::neg;
  using AiOnnxOpset6::pad;
  using AiOnnxOpset6::randomnormal;
  using AiOnnxOpset6::randomnormallike;
  using AiOnnxOpset6::randomuniform;
  using AiOnnxOpset6::randomuniformlike;
  using AiOnnxOpset6::reciprocal;
  using AiOnnxOpset6::reducel1;
  using AiOnnxOpset6::reducel2;
  using AiOnnxOpset6::reducelogsum;
  using AiOnnxOpset6::reducelogsumexp;
  using AiOnnxOpset6::reducemax;
  using AiOnnxOpset6::reducemean;
  using AiOnnxOpset6::reducemin;
  using AiOnnxOpset6::reduceprod;
  using AiOnnxOpset6::reducesum;
  using AiOnnxOpset6::reducesumsquare;
  using AiOnnxOpset6::relu;
  using AiOnnxOpset6::reshape;
  using AiOnnxOpset6::selu;
  using AiOnnxOpset6::shape;
  using AiOnnxOpset6::sigmoid;
  using AiOnnxOpset6::size;
  using AiOnnxOpset6::slice;
  using AiOnnxOpset6::softmax;
  using AiOnnxOpset6::softplus;
  using AiOnnxOpset6::softsign;
  using AiOnnxOpset6::spacetodepth;
  using AiOnnxOpset6::split;
  using AiOnnxOpset6::sqrt;
  using AiOnnxOpset6::squeeze;
  using AiOnnxOpset6::sum;
  using AiOnnxOpset6::tanh;
  using AiOnnxOpset6::tile;
  using AiOnnxOpset6::topk;
  using AiOnnxOpset6::transpose;
  using AiOnnxOpset6::unsqueeze;

  /**
   * Add the 'Acos' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Acos
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId acos(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Add' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Add
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId add(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'And' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#And
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId logical_and(const std::vector<TensorId> &args,
                       const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Asin' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Asin
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId asin(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Atan' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Atan
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId atan(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'AveragePool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#AveragePool-7
   *
   * \param args List of input tensor ids
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param count_include_pad The 'count_include_pad' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  averagepool(const std::vector<TensorId> &args,
              const std::vector<int64_t> &kernel_shape,
              int64_t count_include_pad                = 0,
              const std::vector<int64_t> &pads         = std::vector<int64_t>(),
              const std::vector<int64_t> &strides      = std::vector<int64_t>(),
              const popart::DebugContext &debugContext = {});

  /**
   * Add the 'BatchNormalization' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#BatchNormalization-7
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param epsilon The 'epsilon' attribute
   * \param momentum The 'momentum' attribute
   * \param spatial The 'spatial' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  batchnormalization(const std::vector<TensorId> &args,
                     unsigned num_outputs,
                     float epsilon                            = 1e-05f,
                     float momentum                           = 0.9f,
                     int64_t spatial                          = 1,
                     const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Cos' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Cos
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId cos(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Div' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Div
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId div(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Dropout' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Dropout-7
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param ratio The 'ratio' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId> dropout(const std::vector<TensorId> &args,
                                unsigned num_outputs,
                                float ratio                              = 0.5f,
                                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Equal' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Equal-7
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId equal(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'GRU' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#GRU
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param activation_alpha The 'activation_alpha' attribute
   * \param activation_beta The 'activation_beta' attribute
   * \param activations The 'activations' attribute
   * \param clip The 'clip' attribute
   * \param hidden_size The 'hidden_size' attribute
   * \param direction The 'direction' attribute
   * \param linear_before_reset The 'linear_before_reset' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  gru(const std::vector<TensorId> &args,
      unsigned num_outputs,
      const std::vector<float> &activation_alpha  = std::vector<float>(),
      const std::vector<float> &activation_beta   = std::vector<float>(),
      const std::vector<std::string> &activations = std::vector<std::string>(),
      nonstd::optional<float> clip                = nonstd::optional<float>(),
      const std::string &direction                = "forward",
      nonstd::optional<int64_t> hidden_size       = nonstd::optional<int64_t>(),
      int64_t linear_before_reset                 = 0,
      const popart::DebugContext &debugContext    = {});

  /**
   * Add the 'Gemm' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Gemm-7
   *
   * \param args List of input tensor ids
   * \param alpha The 'alpha' attribute
   * \param beta The 'beta' attribute
   * \param transA The 'transA' attribute
   * \param transB The 'transB' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId gemm(const std::vector<TensorId> &args,
                float alpha                              = 1.0f,
                float beta                               = 1.0f,
                int64_t transA                           = 0,
                int64_t transB                           = 0,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Greater' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Greater-7
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId greater(const std::vector<TensorId> &args,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'LSTM' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#LSTM
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param activation_alpha The 'activation_alpha' attribute
   * \param activation_beta The 'activation_beta' attribute
   * \param activations The 'activations' attribute
   * \param clip The 'clip' attribute
   * \param hidden_size The 'hidden_size' attribute
   * \param direction The 'direction' attribute
   * \param input_forget The 'input_forget' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  lstm(const std::vector<TensorId> &args,
       unsigned num_outputs,
       const std::vector<float> &activation_alpha  = std::vector<float>(),
       const std::vector<float> &activation_beta   = std::vector<float>(),
       const std::vector<std::string> &activations = std::vector<std::string>(),
       nonstd::optional<float> clip                = nonstd::optional<float>(),
       const std::string &direction                = "forward",
       nonstd::optional<int64_t> hidden_size    = nonstd::optional<int64_t>(),
       int64_t input_forget                     = 0,
       const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Less' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Less-7
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId less(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Mul' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mul
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId mul(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Multinomial' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Multinomial
   *
   * \param args List of input tensor ids
   * \param seed The 'seed' attribute
   * \param dtype The 'dtype' attribute
   * \param sample_size The 'sample_size' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId multinomial(const std::vector<TensorId> &args,
                       int64_t dtype                = 6,
                       int64_t sample_size          = 1,
                       nonstd::optional<float> seed = nonstd::optional<float>(),
                       const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Or' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Or
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId logical_or(const std::vector<TensorId> &args,
                      const popart::DebugContext &debugContext = {});

  /**
   * Add the 'PRelu' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#PRelu-7
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId prelu(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Pow' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pow
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId pow(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'RNN' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#RNN
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param activation_alpha The 'activation_alpha' attribute
   * \param activation_beta The 'activation_beta' attribute
   * \param clip The 'clip' attribute
   * \param hidden_size The 'hidden_size' attribute
   * \param activations The 'activations' attribute
   * \param direction The 'direction' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  rnn(const std::vector<TensorId> &args,
      unsigned num_outputs,
      const std::vector<float> &activation_alpha  = std::vector<float>(),
      const std::vector<float> &activation_beta   = std::vector<float>(),
      const std::vector<std::string> &activations = std::vector<std::string>(),
      nonstd::optional<float> clip                = nonstd::optional<float>(),
      const std::string &direction                = "forward",
      nonstd::optional<int64_t> hidden_size       = nonstd::optional<int64_t>(),
      const popart::DebugContext &debugContext    = {});

  /**
   * Add the 'Sin' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sin
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sin(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Sub' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sub
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sub(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Tan' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Tan
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId tan(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Upsample' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Upsample-7
   *
   * \param args List of input tensor ids
   * \param scales The 'scales' attribute
   * \param mode The 'mode' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId upsample(const std::vector<TensorId> &args,
                    const std::vector<float> &scales,
                    const std::string &mode                  = "nearest",
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Xor' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Xor
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId logical_xor(const std::vector<TensorId> &args,
                       const popart::DebugContext &debugContext = {});
};

class AiOnnxOpset8 : private AiOnnxOpset7 {

protected:
  using AiOnnxOpset7::impl;

public:
  AiOnnxOpset8(std::unique_ptr<BuilderImpl> &impl_) : AiOnnxOpset7(impl_) {}

  // return the opset version
  int getOpsetVersion() const override { return 8; }

  using AiOnnxOpset7::abs;
  using AiOnnxOpset7::acos;
  using AiOnnxOpset7::add;
  using AiOnnxOpset7::argmax;
  using AiOnnxOpset7::argmin;
  using AiOnnxOpset7::asin;
  using AiOnnxOpset7::atan;
  using AiOnnxOpset7::averagepool;
  using AiOnnxOpset7::batchnormalization;
  using AiOnnxOpset7::cast;
  using AiOnnxOpset7::ceil;
  using AiOnnxOpset7::clip;
  using AiOnnxOpset7::concat;
  using AiOnnxOpset7::constant;
  using AiOnnxOpset7::conv;
  using AiOnnxOpset7::convtranspose;
  using AiOnnxOpset7::cos;
  using AiOnnxOpset7::depthtospace;
  using AiOnnxOpset7::div;
  using AiOnnxOpset7::dropout;
  using AiOnnxOpset7::elu;
  using AiOnnxOpset7::equal;
  using AiOnnxOpset7::exp;
  using AiOnnxOpset7::flatten;
  using AiOnnxOpset7::floor;
  using AiOnnxOpset7::gather;
  using AiOnnxOpset7::gemm;
  using AiOnnxOpset7::globalaveragepool;
  using AiOnnxOpset7::globallppool;
  using AiOnnxOpset7::globalmaxpool;
  using AiOnnxOpset7::greater;
  using AiOnnxOpset7::gru;
  using AiOnnxOpset7::hardmax;
  using AiOnnxOpset7::hardsigmoid;
  using AiOnnxOpset7::identity;
  using AiOnnxOpset7::instancenormalization;
  using AiOnnxOpset7::leakyrelu;
  using AiOnnxOpset7::less;
  using AiOnnxOpset7::log;
  using AiOnnxOpset7::logical_and;
  using AiOnnxOpset7::logical_if;
  using AiOnnxOpset7::logical_not;
  using AiOnnxOpset7::logical_or;
  using AiOnnxOpset7::logical_xor;
  using AiOnnxOpset7::logsoftmax;
  using AiOnnxOpset7::loop;
  using AiOnnxOpset7::lpnormalization;
  using AiOnnxOpset7::lppool;
  using AiOnnxOpset7::lrn;
  using AiOnnxOpset7::lstm;
  using AiOnnxOpset7::matmul;
  using AiOnnxOpset7::maxroipool;
  using AiOnnxOpset7::mul;
  using AiOnnxOpset7::multinomial;
  using AiOnnxOpset7::neg;
  using AiOnnxOpset7::pad;
  using AiOnnxOpset7::pow;
  using AiOnnxOpset7::prelu;
  using AiOnnxOpset7::randomnormal;
  using AiOnnxOpset7::randomnormallike;
  using AiOnnxOpset7::randomuniform;
  using AiOnnxOpset7::randomuniformlike;
  using AiOnnxOpset7::reciprocal;
  using AiOnnxOpset7::reducel1;
  using AiOnnxOpset7::reducel2;
  using AiOnnxOpset7::reducelogsum;
  using AiOnnxOpset7::reducelogsumexp;
  using AiOnnxOpset7::reducemax;
  using AiOnnxOpset7::reducemean;
  using AiOnnxOpset7::reducemin;
  using AiOnnxOpset7::reduceprod;
  using AiOnnxOpset7::reducesum;
  using AiOnnxOpset7::reducesumsquare;
  using AiOnnxOpset7::relu;
  using AiOnnxOpset7::reshape;
  using AiOnnxOpset7::rnn;
  using AiOnnxOpset7::selu;
  using AiOnnxOpset7::shape;
  using AiOnnxOpset7::sigmoid;
  using AiOnnxOpset7::sin;
  using AiOnnxOpset7::size;
  using AiOnnxOpset7::slice;
  using AiOnnxOpset7::softmax;
  using AiOnnxOpset7::softplus;
  using AiOnnxOpset7::softsign;
  using AiOnnxOpset7::spacetodepth;
  using AiOnnxOpset7::split;
  using AiOnnxOpset7::sqrt;
  using AiOnnxOpset7::squeeze;
  using AiOnnxOpset7::sub;
  using AiOnnxOpset7::tan;
  using AiOnnxOpset7::tanh;
  using AiOnnxOpset7::tile;
  using AiOnnxOpset7::topk;
  using AiOnnxOpset7::transpose;
  using AiOnnxOpset7::unsqueeze;
  using AiOnnxOpset7::upsample;

  /**
   * Add the 'Expand' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Expand
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId expand(const std::vector<TensorId> &args,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Max' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Max
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId max(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'MaxPool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#MaxPool-8
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param storage_order The 'storage_order' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  maxpool(const std::vector<TensorId> &args,
          unsigned num_outputs,
          const std::vector<int64_t> &kernel_shape,
          const std::vector<int64_t> &pads         = std::vector<int64_t>(),
          int64_t storage_order                    = 0,
          const std::vector<int64_t> &strides      = std::vector<int64_t>(),
          const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Mean' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mean
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId mean(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Min' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Min
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId min(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Scan' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Scan-8
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param body The 'body' attribute
   * \param directions The 'directions' attribute
   * \param num_scan_inputs The 'num_scan_inputs' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  std::vector<TensorId>
  scan(const std::vector<TensorId> &args,
       unsigned num_outputs,
       const Builder &body,
       int64_t num_scan_inputs,
       const std::vector<int64_t> &directions   = std::vector<int64_t>(),
       const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Sum' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sum
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sum(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});
};

class AiOnnxOpset9 : private AiOnnxOpset8 {

protected:
  using AiOnnxOpset8::impl;

public:
  AiOnnxOpset9(std::unique_ptr<BuilderImpl> &impl_) : AiOnnxOpset8(impl_) {}

  // return the opset version
  int getOpsetVersion() const override { return 9; }

  using AiOnnxOpset8::abs;
  using AiOnnxOpset8::acos;
  using AiOnnxOpset8::add;
  using AiOnnxOpset8::argmax;
  using AiOnnxOpset8::argmin;
  using AiOnnxOpset8::asin;
  using AiOnnxOpset8::atan;
  using AiOnnxOpset8::averagepool;
  using AiOnnxOpset8::ceil;
  using AiOnnxOpset8::clip;
  using AiOnnxOpset8::concat;
  using AiOnnxOpset8::conv;
  using AiOnnxOpset8::convtranspose;
  using AiOnnxOpset8::cos;
  using AiOnnxOpset8::depthtospace;
  using AiOnnxOpset8::div;
  using AiOnnxOpset8::dropout;
  using AiOnnxOpset8::elu;
  using AiOnnxOpset8::equal;
  using AiOnnxOpset8::exp;
  using AiOnnxOpset8::expand;
  using AiOnnxOpset8::floor;
  using AiOnnxOpset8::gather;
  using AiOnnxOpset8::globalaveragepool;
  using AiOnnxOpset8::globallppool;
  using AiOnnxOpset8::globalmaxpool;
  using AiOnnxOpset8::gru;
  using AiOnnxOpset8::hardmax;
  using AiOnnxOpset8::hardsigmoid;
  using AiOnnxOpset8::identity;
  using AiOnnxOpset8::instancenormalization;
  using AiOnnxOpset8::leakyrelu;
  using AiOnnxOpset8::log;
  using AiOnnxOpset8::logical_and;
  using AiOnnxOpset8::logical_if;
  using AiOnnxOpset8::logical_not;
  using AiOnnxOpset8::logical_or;
  using AiOnnxOpset8::logical_xor;
  using AiOnnxOpset8::logsoftmax;
  using AiOnnxOpset8::loop;
  using AiOnnxOpset8::lpnormalization;
  using AiOnnxOpset8::lppool;
  using AiOnnxOpset8::lrn;
  using AiOnnxOpset8::lstm;
  using AiOnnxOpset8::max;
  using AiOnnxOpset8::maxpool;
  using AiOnnxOpset8::maxroipool;
  using AiOnnxOpset8::mean;
  using AiOnnxOpset8::min;
  using AiOnnxOpset8::mul;
  using AiOnnxOpset8::multinomial;
  using AiOnnxOpset8::neg;
  using AiOnnxOpset8::pad;
  using AiOnnxOpset8::pow;
  using AiOnnxOpset8::randomnormal;
  using AiOnnxOpset8::randomnormallike;
  using AiOnnxOpset8::randomuniform;
  using AiOnnxOpset8::randomuniformlike;
  using AiOnnxOpset8::reciprocal;
  using AiOnnxOpset8::reducel1;
  using AiOnnxOpset8::reducel2;
  using AiOnnxOpset8::reducelogsum;
  using AiOnnxOpset8::reducelogsumexp;
  using AiOnnxOpset8::reducemax;
  using AiOnnxOpset8::reducemean;
  using AiOnnxOpset8::reducemin;
  using AiOnnxOpset8::reduceprod;
  using AiOnnxOpset8::reducesum;
  using AiOnnxOpset8::reducesumsquare;
  using AiOnnxOpset8::relu;
  using AiOnnxOpset8::reshape;
  using AiOnnxOpset8::rnn;
  using AiOnnxOpset8::selu;
  using AiOnnxOpset8::shape;
  using AiOnnxOpset8::sigmoid;
  using AiOnnxOpset8::sin;
  using AiOnnxOpset8::size;
  using AiOnnxOpset8::slice;
  using AiOnnxOpset8::softmax;
  using AiOnnxOpset8::softplus;
  using AiOnnxOpset8::softsign;
  using AiOnnxOpset8::spacetodepth;
  using AiOnnxOpset8::split;
  using AiOnnxOpset8::sqrt;
  using AiOnnxOpset8::squeeze;
  using AiOnnxOpset8::sub;
  using AiOnnxOpset8::sum;
  using AiOnnxOpset8::tan;
  using AiOnnxOpset8::tanh;
  using AiOnnxOpset8::tile;
  using AiOnnxOpset8::topk;
  using AiOnnxOpset8::transpose;
  using AiOnnxOpset8::unsqueeze;

  /**
   * Add the 'Acosh' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Acosh
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId acosh(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Asinh' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Asinh
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId asinh(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Atanh' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Atanh
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId atanh(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'BatchNormalization' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#BatchNormalization
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param epsilon The 'epsilon' attribute
   * \param momentum The 'momentum' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  batchnormalization(const std::vector<TensorId> &args,
                     unsigned num_outputs,
                     float epsilon                            = 1e-05f,
                     float momentum                           = 0.9f,
                     const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Cast' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Cast
   *
   * \param args List of input tensor ids
   * \param to The 'to' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId cast(const std::vector<TensorId> &args,
                const std::string &to,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Compress' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Compress-9
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  compress(const std::vector<TensorId> &args,
           nonstd::optional<int64_t> axis = nonstd::optional<int64_t>(),
           const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Constant' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Constant-9
   *
   * \param value The 'value' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId constant(const ConstVoidData &value,
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ConstantOfShape' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConstantOfShape
   *
   * \param args List of input tensor ids
   * \param value The 'value' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId constantofshape(const std::vector<TensorId> &args,
                           const ConstVoidData &value,
                           const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Cosh' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Cosh
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId cosh(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Erf' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Erf
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId erf(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'EyeLike' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#EyeLike
   *
   * \param args List of input tensor ids
   * \param dtype The 'dtype' attribute
   * \param k The 'k' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  eyelike(const std::vector<TensorId> &args,
          nonstd::optional<int64_t> dtype = nonstd::optional<int64_t>(),
          int64_t k                       = 0,
          const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Flatten' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Flatten-9
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId flatten(const std::vector<TensorId> &args,
                   int64_t axis                             = 1,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Gemm' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Gemm-9
   *
   * \param args List of input tensor ids
   * \param alpha The 'alpha' attribute
   * \param beta The 'beta' attribute
   * \param transA The 'transA' attribute
   * \param transB The 'transB' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId gemm(const std::vector<TensorId> &args,
                float alpha                              = 1.0f,
                float beta                               = 1.0f,
                int64_t transA                           = 0,
                int64_t transB                           = 0,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Greater' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Greater
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId greater(const std::vector<TensorId> &args,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'IsNaN' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#IsNaN
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId isnan(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Less' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Less
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId less(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'MatMul' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#MatMul
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId matmul(const std::vector<TensorId> &args,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'MaxUnpool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#MaxUnpool-9
   *
   * \param args List of input tensor ids
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  maxunpool(const std::vector<TensorId> &args,
            const std::vector<int64_t> &kernel_shape,
            const std::vector<int64_t> &pads         = std::vector<int64_t>(),
            const std::vector<int64_t> &strides      = std::vector<int64_t>(),
            const popart::DebugContext &debugContext = {});

  /**
   * Add the 'MeanVarianceNormalization' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#MeanVarianceNormalization
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId meanvariancenormalization(
      const std::vector<TensorId> &args,
      const std::vector<int64_t> &axes         = std::vector<int64_t>(),
      const popart::DebugContext &debugContext = {});

  /**
   * Add the 'NonZero' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#NonZero
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId nonzero(const std::vector<TensorId> &args,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'OneHot' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#OneHot-9
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId onehot(const std::vector<TensorId> &args,
                  int64_t axis                             = -1,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'PRelu' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#PRelu
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId prelu(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Scan' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Scan-9
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param body The 'body' attribute
   * \param num_scan_inputs The 'num_scan_inputs' attribute
   * \param scan_input_axes The 'scan_input_axes' attribute
   * \param scan_input_directions The 'scan_input_directions' attribute
   * \param scan_output_axes The 'scan_output_axes' attribute
   * \param scan_output_directions The 'scan_output_directions' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  std::vector<TensorId>
  scan(const std::vector<TensorId> &args,
       unsigned num_outputs,
       const Builder &body,
       int64_t num_scan_inputs,
       const std::vector<int64_t> &scan_input_axes = std::vector<int64_t>(),
       const std::vector<int64_t> &scan_input_directions =
           std::vector<int64_t>(),
       const std::vector<int64_t> &scan_output_axes = std::vector<int64_t>(),
       const std::vector<int64_t> &scan_output_directions =
           std::vector<int64_t>(),
       const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Scatter' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Scatter-9
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId scatter(const std::vector<TensorId> &args,
                   int64_t axis                             = 0,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Shrink' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Shrink
   *
   * \param args List of input tensor ids
   * \param bias The 'bias' attribute
   * \param lambd The 'lambd' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId shrink(const std::vector<TensorId> &args,
                  float bias                               = 0.0f,
                  float lambd                              = 0.5f,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Sign' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sign
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sign(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Sinh' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sinh
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sinh(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'TfIdfVectorizer' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#TfIdfVectorizer
   *
   * \param args List of input tensor ids
   * \param max_gram_length The 'max_gram_length' attribute
   * \param max_skip_count The 'max_skip_count' attribute
   * \param min_gram_length The 'min_gram_length' attribute
   * \param mode The 'mode' attribute
   * \param ngram_counts The 'ngram_counts' attribute
   * \param ngram_indexes The 'ngram_indexes' attribute
   * \param pool_int64s The 'pool_int64s' attribute
   * \param pool_strings The 'pool_strings' attribute
   * \param weights The 'weights' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId tfidfvectorizer(
      const std::vector<TensorId> &args,
      int64_t max_gram_length,
      int64_t max_skip_count,
      int64_t min_gram_length,
      const std::string &mode,
      const std::vector<int64_t> &ngram_counts,
      const std::vector<int64_t> &ngram_indexes,
      const std::vector<int64_t> &pool_int64s      = std::vector<int64_t>(),
      const std::vector<std::string> &pool_strings = std::vector<std::string>(),
      const std::vector<float> &weights            = std::vector<float>(),
      const popart::DebugContext &debugContext     = {});

  /**
   * Add the 'Upsample' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Upsample-9
   *
   * \param args List of input tensor ids
   * \param mode The 'mode' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId upsample(const std::vector<TensorId> &args,
                    const std::string &mode                  = "nearest",
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Where' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Where
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId where(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});
};

class AiOnnxOpset10 : private AiOnnxOpset9 {

protected:
  using AiOnnxOpset9::impl;

public:
  AiOnnxOpset10(std::unique_ptr<BuilderImpl> &impl_) : AiOnnxOpset9(impl_) {}

  // return the opset version
  int getOpsetVersion() const override { return 10; }

  using AiOnnxOpset9::abs;
  using AiOnnxOpset9::acos;
  using AiOnnxOpset9::acosh;
  using AiOnnxOpset9::add;
  using AiOnnxOpset9::argmax;
  using AiOnnxOpset9::argmin;
  using AiOnnxOpset9::asin;
  using AiOnnxOpset9::asinh;
  using AiOnnxOpset9::atan;
  using AiOnnxOpset9::atanh;
  using AiOnnxOpset9::batchnormalization;
  using AiOnnxOpset9::cast;
  using AiOnnxOpset9::ceil;
  using AiOnnxOpset9::clip;
  using AiOnnxOpset9::compress;
  using AiOnnxOpset9::concat;
  using AiOnnxOpset9::constant;
  using AiOnnxOpset9::constantofshape;
  using AiOnnxOpset9::conv;
  using AiOnnxOpset9::convtranspose;
  using AiOnnxOpset9::cos;
  using AiOnnxOpset9::cosh;
  using AiOnnxOpset9::depthtospace;
  using AiOnnxOpset9::div;
  using AiOnnxOpset9::elu;
  using AiOnnxOpset9::equal;
  using AiOnnxOpset9::erf;
  using AiOnnxOpset9::exp;
  using AiOnnxOpset9::expand;
  using AiOnnxOpset9::eyelike;
  using AiOnnxOpset9::flatten;
  using AiOnnxOpset9::floor;
  using AiOnnxOpset9::gather;
  using AiOnnxOpset9::gemm;
  using AiOnnxOpset9::globalaveragepool;
  using AiOnnxOpset9::globallppool;
  using AiOnnxOpset9::globalmaxpool;
  using AiOnnxOpset9::greater;
  using AiOnnxOpset9::gru;
  using AiOnnxOpset9::hardmax;
  using AiOnnxOpset9::hardsigmoid;
  using AiOnnxOpset9::identity;
  using AiOnnxOpset9::instancenormalization;
  using AiOnnxOpset9::isnan;
  using AiOnnxOpset9::leakyrelu;
  using AiOnnxOpset9::less;
  using AiOnnxOpset9::log;
  using AiOnnxOpset9::logical_and;
  using AiOnnxOpset9::logical_if;
  using AiOnnxOpset9::logical_not;
  using AiOnnxOpset9::logical_or;
  using AiOnnxOpset9::logical_xor;
  using AiOnnxOpset9::logsoftmax;
  using AiOnnxOpset9::loop;
  using AiOnnxOpset9::lpnormalization;
  using AiOnnxOpset9::lppool;
  using AiOnnxOpset9::lrn;
  using AiOnnxOpset9::lstm;
  using AiOnnxOpset9::matmul;
  using AiOnnxOpset9::max;
  using AiOnnxOpset9::maxroipool;
  using AiOnnxOpset9::maxunpool;
  using AiOnnxOpset9::mean;
  using AiOnnxOpset9::meanvariancenormalization;
  using AiOnnxOpset9::min;
  using AiOnnxOpset9::mul;
  using AiOnnxOpset9::multinomial;
  using AiOnnxOpset9::neg;
  using AiOnnxOpset9::nonzero;
  using AiOnnxOpset9::onehot;
  using AiOnnxOpset9::pad;
  using AiOnnxOpset9::pow;
  using AiOnnxOpset9::prelu;
  using AiOnnxOpset9::randomnormal;
  using AiOnnxOpset9::randomnormallike;
  using AiOnnxOpset9::randomuniform;
  using AiOnnxOpset9::randomuniformlike;
  using AiOnnxOpset9::reciprocal;
  using AiOnnxOpset9::reducel1;
  using AiOnnxOpset9::reducel2;
  using AiOnnxOpset9::reducelogsum;
  using AiOnnxOpset9::reducelogsumexp;
  using AiOnnxOpset9::reducemax;
  using AiOnnxOpset9::reducemean;
  using AiOnnxOpset9::reducemin;
  using AiOnnxOpset9::reduceprod;
  using AiOnnxOpset9::reducesum;
  using AiOnnxOpset9::reducesumsquare;
  using AiOnnxOpset9::relu;
  using AiOnnxOpset9::reshape;
  using AiOnnxOpset9::rnn;
  using AiOnnxOpset9::scan;
  using AiOnnxOpset9::scatter;
  using AiOnnxOpset9::selu;
  using AiOnnxOpset9::shape;
  using AiOnnxOpset9::shrink;
  using AiOnnxOpset9::sigmoid;
  using AiOnnxOpset9::sign;
  using AiOnnxOpset9::sin;
  using AiOnnxOpset9::sinh;
  using AiOnnxOpset9::size;
  using AiOnnxOpset9::softmax;
  using AiOnnxOpset9::softplus;
  using AiOnnxOpset9::softsign;
  using AiOnnxOpset9::spacetodepth;
  using AiOnnxOpset9::split;
  using AiOnnxOpset9::sqrt;
  using AiOnnxOpset9::squeeze;
  using AiOnnxOpset9::sub;
  using AiOnnxOpset9::sum;
  using AiOnnxOpset9::tan;
  using AiOnnxOpset9::tanh;
  using AiOnnxOpset9::tfidfvectorizer;
  using AiOnnxOpset9::tile;
  using AiOnnxOpset9::transpose;
  using AiOnnxOpset9::unsqueeze;
  using AiOnnxOpset9::where;

  /**
   * Add the 'AveragePool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#AveragePool-10
   *
   * \param args List of input tensor ids
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param ceil_mode The 'ceil_mode' attribute
   * \param count_include_pad The 'count_include_pad' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  averagepool(const std::vector<TensorId> &args,
              const std::vector<int64_t> &kernel_shape,
              int64_t ceil_mode                        = 0,
              int64_t count_include_pad                = 0,
              const std::vector<int64_t> &pads         = std::vector<int64_t>(),
              const std::vector<int64_t> &strides      = std::vector<int64_t>(),
              const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ConvInteger' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvInteger
   *
   * \param args List of input tensor ids
   * \param dilations The 'dilations' attribute
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param group The 'group' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  convinteger(const std::vector<TensorId> &args,
              const std::vector<int64_t> &dilations    = std::vector<int64_t>(),
              int64_t group                            = 1,
              const std::vector<int64_t> &kernel_shape = std::vector<int64_t>(),
              const std::vector<int64_t> &pads         = std::vector<int64_t>(),
              const std::vector<int64_t> &strides      = std::vector<int64_t>(),
              const popart::DebugContext &debugContext = {});

  /**
   * Add the 'DequantizeLinear' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#DequantizeLinear
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId dequantizelinear(const std::vector<TensorId> &args,
                            const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Dropout' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Dropout
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param ratio The 'ratio' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId> dropout(const std::vector<TensorId> &args,
                                unsigned num_outputs,
                                float ratio                              = 0.5f,
                                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'IsInf' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#IsInf
   *
   * \param args List of input tensor ids
   * \param detect_negative The 'detect_negative' attribute
   * \param detect_positive The 'detect_positive' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId isinf(const std::vector<TensorId> &args,
                 int64_t detect_negative                  = 1,
                 int64_t detect_positive                  = 1,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'MatMulInteger' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#MatMulInteger
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId matmulinteger(const std::vector<TensorId> &args,
                         const popart::DebugContext &debugContext = {});

  /**
   * Add the 'MaxPool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#MaxPool-10
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param dilations The 'dilations' attribute
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param ceil_mode The 'ceil_mode' attribute
   * \param storage_order The 'storage_order' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  maxpool(const std::vector<TensorId> &args,
          unsigned num_outputs,
          const std::vector<int64_t> &kernel_shape,
          int64_t ceil_mode                        = 0,
          const std::vector<int64_t> &dilations    = std::vector<int64_t>(),
          const std::vector<int64_t> &pads         = std::vector<int64_t>(),
          int64_t storage_order                    = 0,
          const std::vector<int64_t> &strides      = std::vector<int64_t>(),
          const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Mod' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mod
   *
   * \param args List of input tensor ids
   * \param fmod The 'fmod' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId mod(const std::vector<TensorId> &args,
               int64_t fmod                             = 0,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'NonMaxSuppression' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#NonMaxSuppression-10
   *
   * \param args List of input tensor ids
   * \param center_point_box The 'center_point_box' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId nonmaxsuppression(const std::vector<TensorId> &args,
                             int64_t center_point_box                 = 0,
                             const popart::DebugContext &debugContext = {});

  /**
   * Add the 'QLinearConv' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#QLinearConv
   *
   * \param args List of input tensor ids
   * \param dilations The 'dilations' attribute
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param group The 'group' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  qlinearconv(const std::vector<TensorId> &args,
              const std::vector<int64_t> &dilations    = std::vector<int64_t>(),
              int64_t group                            = 1,
              const std::vector<int64_t> &kernel_shape = std::vector<int64_t>(),
              const std::vector<int64_t> &pads         = std::vector<int64_t>(),
              const std::vector<int64_t> &strides      = std::vector<int64_t>(),
              const popart::DebugContext &debugContext = {});

  /**
   * Add the 'QLinearMatMul' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#QLinearMatMul
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId qlinearmatmul(const std::vector<TensorId> &args,
                         const popart::DebugContext &debugContext = {});

  /**
   * Add the 'QuantizeLinear' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#QuantizeLinear
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId quantizelinear(const std::vector<TensorId> &args,
                          const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Resize' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Resize-10
   *
   * \param args List of input tensor ids
   * \param mode The 'mode' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId resize(const std::vector<TensorId> &args,
                  const std::string &mode                  = "nearest",
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReverseSequence' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReverseSequence
   *
   * \param args List of input tensor ids
   * \param batch_axis The 'batch_axis' attribute
   * \param time_axis The 'time_axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reversesequence(const std::vector<TensorId> &args,
                           int64_t batch_axis                       = 1,
                           int64_t time_axis                        = 0,
                           const popart::DebugContext &debugContext = {});

  /**
   * Add the 'RoiAlign' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#RoiAlign
   *
   * \param args List of input tensor ids
   * \param mode The 'mode' attribute
   * \param output_height The 'output_height' attribute
   * \param output_width The 'output_width' attribute
   * \param sampling_ratio The 'sampling_ratio' attribute
   * \param spatial_scale The 'spatial_scale' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId roialign(const std::vector<TensorId> &args,
                    const std::string &mode                  = "avg",
                    int64_t output_height                    = 1,
                    int64_t output_width                     = 1,
                    int64_t sampling_ratio                   = 0,
                    float spatial_scale                      = 1.0f,
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Slice' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Slice-10
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId slice(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'StringNormalizer' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#StringNormalizer
   *
   * \param args List of input tensor ids
   * \param locale The 'locale' attribute
   * \param stopwords The 'stopwords' attribute
   * \param case_change_action The 'case_change_action' attribute
   * \param is_case_sensitive The 'is_case_sensitive' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId stringnormalizer(
      const std::vector<TensorId> &args,
      const std::string &case_change_action     = "NONE",
      int64_t is_case_sensitive                 = 0,
      nonstd::optional<std::string> locale      = std::string(),
      const std::vector<std::string> &stopwords = std::vector<std::string>(),
      const popart::DebugContext &debugContext  = {});

  /**
   * Add the 'ThresholdedRelu' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ThresholdedRelu
   *
   * \param args List of input tensor ids
   * \param alpha The 'alpha' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId thresholdedrelu(const std::vector<TensorId> &args,
                           float alpha                              = 1.0f,
                           const popart::DebugContext &debugContext = {});

  /**
   * Add the 'TopK' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Changelog.md#TopK-10
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId> topk(const std::vector<TensorId> &args,
                             int64_t axis                             = -1,
                             const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Upsample' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Upsample
   *
   * \param args List of input tensor ids
   * \param mode The 'mode' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId upsample(const std::vector<TensorId> &args,
                    const std::string &mode                  = "nearest",
                    const popart::DebugContext &debugContext = {});
};

class AiOnnxOpset11 : private AiOnnxOpset10 {

protected:
  using AiOnnxOpset10::impl;

public:
  AiOnnxOpset11(std::unique_ptr<BuilderImpl> &impl_) : AiOnnxOpset10(impl_) {}

  // return the opset version
  int getOpsetVersion() const override { return 11; }

  using AiOnnxOpset10::abs;
  using AiOnnxOpset10::acos;
  using AiOnnxOpset10::acosh;
  using AiOnnxOpset10::add;
  using AiOnnxOpset10::asin;
  using AiOnnxOpset10::asinh;
  using AiOnnxOpset10::atan;
  using AiOnnxOpset10::atanh;
  using AiOnnxOpset10::batchnormalization;
  using AiOnnxOpset10::cast;
  using AiOnnxOpset10::ceil;
  using AiOnnxOpset10::constantofshape;
  using AiOnnxOpset10::convinteger;
  using AiOnnxOpset10::cos;
  using AiOnnxOpset10::cosh;
  using AiOnnxOpset10::dequantizelinear;
  using AiOnnxOpset10::div;
  using AiOnnxOpset10::dropout;
  using AiOnnxOpset10::elu;
  using AiOnnxOpset10::erf;
  using AiOnnxOpset10::exp;
  using AiOnnxOpset10::expand;
  using AiOnnxOpset10::eyelike;
  using AiOnnxOpset10::floor;
  using AiOnnxOpset10::globalaveragepool;
  using AiOnnxOpset10::globallppool;
  using AiOnnxOpset10::globalmaxpool;
  using AiOnnxOpset10::greater;
  using AiOnnxOpset10::gru;
  using AiOnnxOpset10::hardsigmoid;
  using AiOnnxOpset10::identity;
  using AiOnnxOpset10::instancenormalization;
  using AiOnnxOpset10::isinf;
  using AiOnnxOpset10::isnan;
  using AiOnnxOpset10::leakyrelu;
  using AiOnnxOpset10::less;
  using AiOnnxOpset10::log;
  using AiOnnxOpset10::logical_and;
  using AiOnnxOpset10::logical_not;
  using AiOnnxOpset10::logical_or;
  using AiOnnxOpset10::logical_xor;
  using AiOnnxOpset10::lpnormalization;
  using AiOnnxOpset10::lrn;
  using AiOnnxOpset10::lstm;
  using AiOnnxOpset10::matmul;
  using AiOnnxOpset10::matmulinteger;
  using AiOnnxOpset10::max;
  using AiOnnxOpset10::maxroipool;
  using AiOnnxOpset10::mean;
  using AiOnnxOpset10::meanvariancenormalization;
  using AiOnnxOpset10::min;
  using AiOnnxOpset10::mod;
  using AiOnnxOpset10::mul;
  using AiOnnxOpset10::multinomial;
  using AiOnnxOpset10::neg;
  using AiOnnxOpset10::nonzero;
  using AiOnnxOpset10::pow;
  using AiOnnxOpset10::prelu;
  using AiOnnxOpset10::qlinearconv;
  using AiOnnxOpset10::qlinearmatmul;
  using AiOnnxOpset10::quantizelinear;
  using AiOnnxOpset10::randomnormal;
  using AiOnnxOpset10::randomnormallike;
  using AiOnnxOpset10::randomuniform;
  using AiOnnxOpset10::randomuniformlike;
  using AiOnnxOpset10::reciprocal;
  using AiOnnxOpset10::relu;
  using AiOnnxOpset10::reshape;
  using AiOnnxOpset10::reversesequence;
  using AiOnnxOpset10::rnn;
  using AiOnnxOpset10::roialign;
  using AiOnnxOpset10::selu;
  using AiOnnxOpset10::shape;
  using AiOnnxOpset10::shrink;
  using AiOnnxOpset10::sigmoid;
  using AiOnnxOpset10::sign;
  using AiOnnxOpset10::sin;
  using AiOnnxOpset10::sinh;
  using AiOnnxOpset10::size;
  using AiOnnxOpset10::softplus;
  using AiOnnxOpset10::softsign;
  using AiOnnxOpset10::spacetodepth;
  using AiOnnxOpset10::sqrt;
  using AiOnnxOpset10::stringnormalizer;
  using AiOnnxOpset10::sub;
  using AiOnnxOpset10::sum;
  using AiOnnxOpset10::tan;
  using AiOnnxOpset10::tanh;
  using AiOnnxOpset10::tfidfvectorizer;
  using AiOnnxOpset10::thresholdedrelu;
  using AiOnnxOpset10::tile;
  using AiOnnxOpset10::transpose;
  using AiOnnxOpset10::upsample;
  using AiOnnxOpset10::where;

  /**
   * Add the 'ArgMax' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ArgMax
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId argmax(const std::vector<TensorId> &args,
                  int64_t axis                             = 0,
                  int64_t keepdims                         = 1,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ArgMin' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ArgMin
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId argmin(const std::vector<TensorId> &args,
                  int64_t axis                             = 0,
                  int64_t keepdims                         = 1,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'AveragePool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#AveragePool
   *
   * \param args List of input tensor ids
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param ceil_mode The 'ceil_mode' attribute
   * \param count_include_pad The 'count_include_pad' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  averagepool(const std::vector<TensorId> &args,
              const std::vector<int64_t> &kernel_shape,
              int64_t ceil_mode                        = 0,
              int64_t count_include_pad                = 0,
              const std::vector<int64_t> &pads         = std::vector<int64_t>(),
              const std::vector<int64_t> &strides      = std::vector<int64_t>(),
              const popart::DebugContext &debugContext = {});

  /**
   * Add the 'BitShift' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitShift
   *
   * \param args List of input tensor ids
   * \param direction The 'direction' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId bitshift(const std::vector<TensorId> &args,
                    const std::string &direction,
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Clip' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Clip
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId clip(const std::vector<TensorId> &args,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Compress' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Compress
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  compress(const std::vector<TensorId> &args,
           nonstd::optional<int64_t> axis = nonstd::optional<int64_t>(),
           const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Concat' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Concat
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId concat(const std::vector<TensorId> &args,
                  int64_t axis,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ConcatFromSequence' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConcatFromSequence
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param new_axis The 'new_axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId concatfromsequence(const std::vector<TensorId> &args,
                              int64_t axis,
                              int64_t new_axis                         = 0,
                              const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Constant' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Constant
   *
   * \param value The 'value' attribute"
   * \param is_value_sparse If true, set the 'sparse_value' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId constant(const ConstVoidData &value,
                    bool is_value_sparse             = false,
                    const DebugContext &debugContext = {});

  /**
   * Add the 'Conv' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Conv
   *
   * \param args List of input tensor ids
   * \param dilations The 'dilations' attribute
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param group The 'group' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  conv(const std::vector<TensorId> &args,
       const std::vector<int64_t> &dilations    = std::vector<int64_t>(),
       int64_t group                            = 1,
       const std::vector<int64_t> &kernel_shape = std::vector<int64_t>(),
       const std::vector<int64_t> &pads         = std::vector<int64_t>(),
       const std::vector<int64_t> &strides      = std::vector<int64_t>(),
       const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ConvTranspose' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvTranspose
   *
   * \param args List of input tensor ids
   * \param dilations The 'dilations' attribute
   * \param kernel_shape The 'kernel_shape' attribute
   * \param output_padding The 'output_padding' attribute
   * \param output_shape The 'output_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param group The 'group' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId convtranspose(
      const std::vector<TensorId> &args,
      const std::vector<int64_t> &dilations      = std::vector<int64_t>(),
      int64_t group                              = 1,
      const std::vector<int64_t> &kernel_shape   = std::vector<int64_t>(),
      const std::vector<int64_t> &output_padding = std::vector<int64_t>(),
      const std::vector<int64_t> &output_shape   = std::vector<int64_t>(),
      const std::vector<int64_t> &pads           = std::vector<int64_t>(),
      const std::vector<int64_t> &strides        = std::vector<int64_t>(),
      const popart::DebugContext &debugContext   = {});

  /**
   * Add the 'CumSum' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#CumSum
   *
   * \param args List of input tensor ids
   * \param exclusive The 'exclusive' attribute
   * \param reverse The 'reverse' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId cumsum(const std::vector<TensorId> &args,
                  int64_t exclusive                        = 0,
                  int64_t reverse                          = 0,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'DepthToSpace' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#DepthToSpace
   *
   * \param args List of input tensor ids
   * \param blocksize The 'blocksize' attribute
   * \param mode The 'mode' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId depthtospace(const std::vector<TensorId> &args,
                        int64_t blocksize,
                        const std::string &mode                  = "DCR",
                        const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Det' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Det
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId det(const std::vector<TensorId> &args,
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'DynamicQuantizeLinear' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#DynamicQuantizeLinear
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  dynamicquantizelinear(const std::vector<TensorId> &args,
                        const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Equal' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Equal
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId equal(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Flatten' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Flatten
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId flatten(const std::vector<TensorId> &args,
                   int64_t axis                             = 1,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Gather' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Gather
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId gather(const std::vector<TensorId> &args,
                  int64_t axis                             = 0,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'GatherElements' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherElements
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId gatherelements(const std::vector<TensorId> &args,
                          int64_t axis                             = 0,
                          const popart::DebugContext &debugContext = {});

  /**
   * Add the 'GatherND' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherND
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId gathernd(const std::vector<TensorId> &args,
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Gemm' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Gemm
   *
   * \param args List of input tensor ids
   * \param alpha The 'alpha' attribute
   * \param beta The 'beta' attribute
   * \param transA The 'transA' attribute
   * \param transB The 'transB' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId gemm(const std::vector<TensorId> &args,
                float alpha                              = 1.0f,
                float beta                               = 1.0f,
                int64_t transA                           = 0,
                int64_t transB                           = 0,
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Hardmax' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Hardmax
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId hardmax(const std::vector<TensorId> &args,
                   int64_t axis                             = 1,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'If' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#If
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param else_branch The 'else_branch' attribute
   * \param then_branch The 'then_branch' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  std::vector<TensorId>
  logical_if(const std::vector<TensorId> &args,
             unsigned num_outputs,
             const Builder &else_branch,
             const Builder &then_branch,
             const popart::DebugContext &debugContext = {});

  /**
   * Add the 'LogSoftmax' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#LogSoftmax
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId logsoftmax(const std::vector<TensorId> &args,
                      int64_t axis                             = 1,
                      const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Loop' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Loop
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param body The 'body' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  std::vector<TensorId> loop(const std::vector<TensorId> &args,
                             unsigned num_outputs,
                             const Builder &body,
                             const popart::DebugContext &debugContext = {});

  /**
   * Add the 'LpPool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#LpPool
   *
   * \param args List of input tensor ids
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param p The 'p' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId lppool(const std::vector<TensorId> &args,
                  const std::vector<int64_t> &kernel_shape,
                  int64_t p                           = 2,
                  const std::vector<int64_t> &pads    = std::vector<int64_t>(),
                  const std::vector<int64_t> &strides = std::vector<int64_t>(),
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'MaxPool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#MaxPool
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param dilations The 'dilations' attribute
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param ceil_mode The 'ceil_mode' attribute
   * \param storage_order The 'storage_order' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  maxpool(const std::vector<TensorId> &args,
          unsigned num_outputs,
          const std::vector<int64_t> &kernel_shape,
          int64_t ceil_mode                        = 0,
          const std::vector<int64_t> &dilations    = std::vector<int64_t>(),
          const std::vector<int64_t> &pads         = std::vector<int64_t>(),
          int64_t storage_order                    = 0,
          const std::vector<int64_t> &strides      = std::vector<int64_t>(),
          const popart::DebugContext &debugContext = {});

  /**
   * Add the 'MaxUnpool' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#MaxUnpool
   *
   * \param args List of input tensor ids
   * \param kernel_shape The 'kernel_shape' attribute
   * \param pads The 'pads' attribute
   * \param strides The 'strides' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  maxunpool(const std::vector<TensorId> &args,
            const std::vector<int64_t> &kernel_shape,
            const std::vector<int64_t> &pads         = std::vector<int64_t>(),
            const std::vector<int64_t> &strides      = std::vector<int64_t>(),
            const popart::DebugContext &debugContext = {});

  /**
   * Add the 'NonMaxSuppression' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#NonMaxSuppression
   *
   * \param args List of input tensor ids
   * \param center_point_box The 'center_point_box' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId nonmaxsuppression(const std::vector<TensorId> &args,
                             int64_t center_point_box                 = 0,
                             const popart::DebugContext &debugContext = {});

  /**
   * Add the 'OneHot' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#OneHot
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId onehot(const std::vector<TensorId> &args,
                  int64_t axis                             = -1,
                  const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Pad' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pad
   *
   * \param args List of input tensor ids
   * \param mode The 'mode' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId pad(const std::vector<TensorId> &args,
               const std::string &mode                  = "constant",
               const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Range' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Range
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId range(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceL1' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceL1
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducel1(const std::vector<TensorId> &args,
                    nonstd::optional<std::vector<int64_t>> axes =
                        nonstd::optional<std::vector<int64_t>>(),
                    int64_t keepdims                         = 1,
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceL2' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceL2
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducel2(const std::vector<TensorId> &args,
                    nonstd::optional<std::vector<int64_t>> axes =
                        nonstd::optional<std::vector<int64_t>>(),
                    int64_t keepdims                         = 1,
                    const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceLogSum' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceLogSum
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducelogsum(const std::vector<TensorId> &args,
                        nonstd::optional<std::vector<int64_t>> axes =
                            nonstd::optional<std::vector<int64_t>>(),
                        int64_t keepdims                         = 1,
                        const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceLogSumExp' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceLogSumExp
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducelogsumexp(const std::vector<TensorId> &args,
                           nonstd::optional<std::vector<int64_t>> axes =
                               nonstd::optional<std::vector<int64_t>>(),
                           int64_t keepdims                         = 1,
                           const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceMax' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceMax
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducemax(const std::vector<TensorId> &args,
                     nonstd::optional<std::vector<int64_t>> axes =
                         nonstd::optional<std::vector<int64_t>>(),
                     int64_t keepdims                         = 1,
                     const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceMean' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceMean
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducemean(const std::vector<TensorId> &args,
                      nonstd::optional<std::vector<int64_t>> axes =
                          nonstd::optional<std::vector<int64_t>>(),
                      int64_t keepdims                         = 1,
                      const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceMin' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceMin
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducemin(const std::vector<TensorId> &args,
                     nonstd::optional<std::vector<int64_t>> axes =
                         nonstd::optional<std::vector<int64_t>>(),
                     int64_t keepdims                         = 1,
                     const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceProd' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceProd
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reduceprod(const std::vector<TensorId> &args,
                      nonstd::optional<std::vector<int64_t>> axes =
                          nonstd::optional<std::vector<int64_t>>(),
                      int64_t keepdims                         = 1,
                      const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceSum' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceSum
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducesum(const std::vector<TensorId> &args,
                     nonstd::optional<std::vector<int64_t>> axes =
                         nonstd::optional<std::vector<int64_t>>(),
                     int64_t keepdims                         = 1,
                     const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ReduceSumSquare' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceSumSquare
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId reducesumsquare(const std::vector<TensorId> &args,
                           nonstd::optional<std::vector<int64_t>> axes =
                               nonstd::optional<std::vector<int64_t>>(),
                           int64_t keepdims                         = 1,
                           const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Resize' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Resize
   *
   * \param args List of input tensor ids
   * \param coordinate_transformation_mode The 'coordinate_transformation_mode'
   * attribute \param cubic_coeff_a The 'cubic_coeff_a' attribute \param
   * exclude_outside The 'exclude_outside' attribute \param extrapolation_value
   * The 'extrapolation_value' attribute \param mode The 'mode' attribute \param
   * nearest_mode The 'nearest_mode' attribute \param name Optional identifier
   * for the operation \return The normalized output tensor ids
   */
  TensorId
  resize(const std::vector<TensorId> &args,
         const std::string &coordinate_transformation_mode = "half_pixel",
         float cubic_coeff_a                               = -0.75f,
         int64_t exclude_outside                           = 0,
         float extrapolation_value                         = 0.0f,
         const std::string &mode                           = "nearest",
         const std::string &nearest_mode          = "round_prefer_floor",
         const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Round' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Round
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId round(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Scan' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Scan
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param body The 'body' attribute
   * \param num_scan_inputs The 'num_scan_inputs' attribute
   * \param scan_input_axes The 'scan_input_axes' attribute
   * \param scan_input_directions The 'scan_input_directions' attribute
   * \param scan_output_axes The 'scan_output_axes' attribute
   * \param scan_output_directions The 'scan_output_directions' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  std::vector<TensorId>
  scan(const std::vector<TensorId> &args,
       unsigned num_outputs,
       const Builder &body,
       int64_t num_scan_inputs,
       const std::vector<int64_t> &scan_input_axes = std::vector<int64_t>(),
       const std::vector<int64_t> &scan_input_directions =
           std::vector<int64_t>(),
       const std::vector<int64_t> &scan_output_axes = std::vector<int64_t>(),
       const std::vector<int64_t> &scan_output_directions =
           std::vector<int64_t>(),
       const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Scatter' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Scatter
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId scatter(const std::vector<TensorId> &args,
                   int64_t axis                             = 0,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ScatterElements' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ScatterElements
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId scatterelements(const std::vector<TensorId> &args,
                           int64_t axis                             = 0,
                           const popart::DebugContext &debugContext = {});

  /**
   * Add the 'ScatterND' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#ScatterND
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId scatternd(const std::vector<TensorId> &args,
                     const popart::DebugContext &debugContext = {});

  /**
   * Add the 'SequenceAt' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceAt
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sequenceat(const std::vector<TensorId> &args,
                      const popart::DebugContext &debugContext = {});

  /**
   * Add the 'SequenceConstruct' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceConstruct
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sequenceconstruct(const std::vector<TensorId> &args,
                             const popart::DebugContext &debugContext = {});

  /**
   * Add the 'SequenceEmpty' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceEmpty
   *
   * \param dtype The 'dtype' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId
  sequenceempty(nonstd::optional<int64_t> dtype = nonstd::optional<int64_t>(),
                const popart::DebugContext &debugContext = {});

  /**
   * Add the 'SequenceErase' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceErase
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sequenceerase(const std::vector<TensorId> &args,
                         const popart::DebugContext &debugContext = {});

  /**
   * Add the 'SequenceInsert' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceInsert
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sequenceinsert(const std::vector<TensorId> &args,
                          const popart::DebugContext &debugContext = {});

  /**
   * Add the 'SequenceLength' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceLength
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId sequencelength(const std::vector<TensorId> &args,
                          const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Slice' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Slice
   *
   * \param args List of input tensor ids
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId slice(const std::vector<TensorId> &args,
                 const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Softmax' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Softmax
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId softmax(const std::vector<TensorId> &args,
                   int64_t axis                             = 1,
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Split' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Split
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param split The 'split' attribute
   * \param axis The 'axis' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  std::vector<TensorId>
  split(const std::vector<TensorId> &args,
        unsigned num_outputs,
        int64_t axis                             = 0,
        const std::vector<int64_t> &split        = std::vector<int64_t>(),
        const popart::DebugContext &debugContext = {});

  /**
   * Add the 'SplitToSequence' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#SplitToSequence
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param keepdims The 'keepdims' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId splittosequence(const std::vector<TensorId> &args,
                           int64_t axis                             = 0,
                           int64_t keepdims                         = 1,
                           const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Squeeze' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Squeeze
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId squeeze(const std::vector<TensorId> &args,
                   const std::vector<int64_t> &axes = std::vector<int64_t>(),
                   const popart::DebugContext &debugContext = {});

  /**
   * Add the 'TopK' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#TopK
   *
   * \param args List of input tensor ids
   * \param axis The 'axis' attribute
   * \param largest The 'largest' attribute
   * \param sorted The 'sorted' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId> topk(const std::vector<TensorId> &args,
                             int64_t axis                             = -1,
                             int64_t largest                          = 1,
                             int64_t sorted                           = 1,
                             const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Unique' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Unique
   *
   * \param args List of input tensor ids
   * \param num_outputs The number of output tensor ids
   * \param axis The 'axis' attribute
   * \param sorted The 'sorted' attribute
   * \param name Optional identifier for the operation
   * \return A list of normalized output tensors
   */
  std::vector<TensorId>
  unique(const std::vector<TensorId> &args,
         unsigned num_outputs,
         nonstd::optional<int64_t> axis           = nonstd::optional<int64_t>(),
         int64_t sorted                           = 1,
         const popart::DebugContext &debugContext = {});

  /**
   * Add the 'Unsqueeze' to the model
   *
   * https://github.com/onnx/onnx/blob/master/docs/Operators.md#Unsqueeze
   *
   * \param args List of input tensor ids
   * \param axes The 'axes' attribute
   * \param name Optional identifier for the operation
   * \return The normalized output tensor ids
   */
  TensorId unsqueeze(const std::vector<TensorId> &args,
                     const std::vector<int64_t> &axes,
                     const popart::DebugContext &debugContext = {});
};

} // namespace popart
#endif
